{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "# version 3\n",
    "from trade_algorithm import indicators\n",
    "from tvDatafeed import TvDatafeed\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pythainav as nav\n",
    "from utils import get_data, load_data\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "tv = TvDatafeed(username=None,password=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exchange: HAVE_DIVIDEND\n",
      "len data: 224\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 219\n",
      "len data: 227\n",
      "len data: 221\n",
      "len data: 231\n",
      "len data: 231\n",
      "len data: 232\n",
      "len data: 232\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 224\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 219\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 232\n",
      "len data: 217\n",
      "len data: 243\n",
      "len data: 222\n",
      "len data: 218\n",
      "len data: 224\n",
      "len data: 219\n",
      "len data: 222\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 215\n",
      "len data: 219\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 221\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 227\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 234\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 242\n",
      "len data: 243\n",
      "len data: 227\n",
      "len data: 227\n",
      "len data: 227\n",
      "len data: 227\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 213\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 231\n",
      "len data: 243\n",
      "len data: 215\n",
      "len data: 218\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 242\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 212\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 243\n",
      "len data: 214\n",
      "len data: 214\n",
      "len data: 206\n",
      "len data: 206\n",
      "len data: 198\n",
      "len data: 198\n",
      "len data: 180\n",
      "len data: 25\n",
      "len data: 105\n",
      "len data: 105\n",
      "len data: 105\n",
      "len data: 78\n",
      "len data: 78\n",
      "len data: 62\n",
      "len data: 62\n",
      "len data: 31\n",
      "List stock name of the lowest close value in the 62 days\n",
      "ASP-PRE-UI-D 10\n",
      "stock min day: ['ASP-PRE-UI-D']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "List stock name of the lowest close value in the 93 days\n",
      "ASP-PRE-UI-D 10\n",
      "stock min day: ['ASP-PRE-UI-D', 'ASP-PRE-UI-D']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "List stock name of the lowest close value in the 124 days\n",
      "ASP-PRE-UI-D 10\n",
      "stock min day: ['ASP-PRE-UI-D', 'ASP-PRE-UI-D', 'ASP-PRE-UI-D']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "days: 124\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LHDEBT-D 30.19412896067704\n",
      "KTFIXPLUS-D 25.18019626014998\n",
      "ONE-UGG-ASSF 19.64304239207782\n",
      "UOBSCI-D 18.602173137198445\n",
      "UOBSCI-N 16.572450042740716\n",
      "ONE-UGG-IA 15.642113545376018\n",
      "KFHHCARE-D 14.539940408177573\n",
      "ONE-ALLCHINA-ASSF 12.588240436671384\n",
      "K-USA-A(D) 12.536225021370358\n",
      "ONE-UGG-RA 11.634682771761586\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The name of the stock that has reached the lowest price in [62, 93, 124] days\n",
      "the name of stock is trend up\n",
      "ASP-PRE-UI-D 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list stock config\n",
    "with open(os.path.join(os.getcwd(),'config','list_stock','stock_config.json')) as f:\n",
    "    json_stock = json.load(f)\n",
    "\n",
    "assert json_stock is not None, \"error read stock config\"\n",
    "\n",
    "# indicator config for long term\n",
    "with open(os.path.join(os.getcwd(),'config','indicator','long_indicator.json')) as f:\n",
    "    indicator_config_long = json.load(f)\n",
    "\n",
    "assert indicator_config_long is not None, \"error read indicator config (long term)\"\n",
    "\n",
    "# indicator config for short term\n",
    "with open(os.path.join(os.getcwd(),'config','indicator','short_indicator.json')) as f:\n",
    "    indicator_config_short = json.load(f)\n",
    "\n",
    "assert indicator_config_short is not None, \"error read indicator config (short term)\"\n",
    "\n",
    "# config\n",
    "with open(os.path.join(os.getcwd(),'config','config.json')) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "assert config is not None, \"error read config\"\n",
    "\n",
    "\n",
    "# find current date\n",
    "current_date = datetime.datetime.today().date()\n",
    "\n",
    "indicator_engine = indicators()\n",
    "\n",
    "# prepare config\n",
    "mode = config['mode']\n",
    "max_days = config[mode]['len_data']\n",
    "max_days = max(max_days)\n",
    "\n",
    "for key_exc in json_stock[f'list_{mode}']:\n",
    "    print(f'exchange: {key_exc}')\n",
    "\n",
    "    dict_min_value_1 = {}\n",
    "    dict_min_value_2 = {}\n",
    "    dict_remaining_date = {}\n",
    "    dict_pair_daywithscore = {\n",
    "        \"stock_score\":[],\n",
    "        \"min_date\":[]\n",
    "    }\n",
    "\n",
    "    dict_stock_name_score = {}\n",
    "    for namest2dict in json_stock[f'list_{mode}'][key_exc]:\n",
    "        dict_stock_name_score.update({namest2dict:0})\n",
    "        dict_remaining_date.update({namest2dict:{}})\n",
    "        for t in config[mode]['len_data']:\n",
    "            dict_remaining_date[namest2dict].update({f\"{t}\":0})\n",
    "\n",
    "    for namest in json_stock[f'list_{mode}'][key_exc]:\n",
    "        if config['fetch_newdata'] == \"on\":\n",
    "            try:\n",
    "                data = get_data(tv, nav, key_exc, namest, max_days, mode)\n",
    "                print(\"len data:\",len(data))\n",
    "                if len(data) == 0:\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f'stock name: {namest}')\n",
    "                print(f'error: {e}')\n",
    "                continue\n",
    "        else:\n",
    "            data_follow_time = load_data(namest, mode, key_exc, t)\n",
    "\n",
    "        score = 0\n",
    "        # first indicators\n",
    "        for indicator in config[mode]['long_indicators']:\n",
    "            # print('indicator:',indicator)\n",
    "            score += indicator_engine.process(f\"{indicator}\", data, indicator_config_long[f'{indicator}'])\n",
    "        \n",
    "        # print('score:',score)\n",
    "        dict_stock_name_score[namest] = score\n",
    "\n",
    "        for t in config[mode]['len_data']:\n",
    "            data_follow_time = load_data(namest, mode, key_exc, t)\n",
    "            \n",
    "            # data_follow_time = get_data(tv, key_exc, namest, t)\n",
    "            # data_follow_time = data_follow_time.reset_index()\n",
    "\n",
    "            # find min value in dataframe\n",
    "            data_cal_number_days = data_follow_time[data_follow_time['close'] == min(list(data_follow_time['close']))]\n",
    "            # convert timestamp to datetime.date\n",
    "            if len(data_cal_number_days) > 1:\n",
    "                data_cal_number_days = data_cal_number_days.iloc[-1,:]\n",
    "                date_min_value = data_cal_number_days['datetime'].to_pydatetime().date()\n",
    "            else:\n",
    "                # convert numpy.datetime64 to datetime\n",
    "                date_min_value = pd.to_datetime(data_cal_number_days['datetime'].values[0]).to_pydatetime().date()\n",
    "            # date_min_value = data_cal_number_days['datetime'].to_pydatetime().date()\n",
    "            remaining_date = current_date - date_min_value\n",
    "            \n",
    "            df_min_value = data_follow_time[data_follow_time['close'] == min(list(data_follow_time['close']))]\n",
    "            df_current_value = data_follow_time.iloc[-2:-1,:]\n",
    "            if t == 62:\n",
    "                dict_remaining_date[namest][f'{t}'] = remaining_date.days\n",
    "                dict_min_value_1[namest] = df_current_value['close'].values[0] - min(list(data_follow_time['close']))\n",
    "            else:\n",
    "                dict_remaining_date[namest][f'{t}'] = remaining_date.days\n",
    "                dict_min_value_2[namest] = df_current_value['close'].values[0] - min(list(data_follow_time['close']))\n",
    "\n",
    "    # sort data by current close value minus the smallest a value in the past\n",
    "    dict_min_value_1_sort = dict(sorted(dict_min_value_1.items(), key=lambda item: item[1], reverse=True))\n",
    "    dict_min_value_2_sort = dict(sorted(dict_min_value_2.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # increse score following by date\n",
    "    dict_prepare_sort = {}\n",
    "    score_follow_time = 0.5\n",
    "    for data_v in config[mode]['len_data']:\n",
    "        for key,_ in dict_remaining_date.items():\n",
    "            dict_prepare_sort[key] = dict_remaining_date[key][f\"{data_v}\"]\n",
    "        \n",
    "        dict_remaining_date_sort = dict(sorted(dict_prepare_sort.items(), key=lambda item: item[1],reverse=True))\n",
    "        list_score = [i+score_follow_time for i in range(10)]\n",
    "\n",
    "        reverse_date_tomin_first = dict(sorted(dict_remaining_date_sort.items(), key=lambda item: item[1]))\n",
    "        \n",
    "        print(f'List stock name of the lowest close value in the {data_v} days')\n",
    "        for k,v in reverse_date_tomin_first.items():\n",
    "            if int(v) <= 10:\n",
    "                dict_pair_daywithscore['min_date'].append(k)\n",
    "                print(k,v)\n",
    "        print('stock min day:',dict_pair_daywithscore['min_date'])\n",
    "        print('-'*100)\n",
    "\n",
    "        for add_score, key_score in zip(list_score,list(dict_remaining_date_sort.keys())[:10]):\n",
    "            dict_stock_name_score[key_score] = dict_stock_name_score[key_score] + add_score\n",
    "\n",
    "        score_follow_time+=0.5        \n",
    "        \n",
    "        # loop increase score\n",
    "    for dict_sort_value in [dict_min_value_1_sort, dict_min_value_2_sort]:\n",
    "        # print('dict_sort_value:',dict_sort_value)\n",
    "        # normalize score\n",
    "        list_score = [i*1000 for i in range(1,len(dict_sort_value)+1)]\n",
    "        np_score = np.array(list_score)\n",
    "        normalized_arr = preprocessing.normalize([np_score])\n",
    "        # print('normalize:',normalized_arr.tolist()[0])\n",
    "\n",
    "        dict_score = {} \n",
    "        for score,(k,v) in zip(normalized_arr.tolist()[0],dict_sort_value.items()):\n",
    "            dict_score.update({k:score})\n",
    "\n",
    "        # print('dict_score:',dict_score)\n",
    "        for k,v in dict_score.items():\n",
    "            dict_stock_name_score[k] = dict_stock_name_score[k] + dict_score[k]\n",
    "\n",
    "\n",
    "    # print('score:',dict_stock_name_score)\n",
    "    dict_stock_name_score_sort = dict(sorted(dict_stock_name_score.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # print('dict_stock_name_score_sort final:',dict_stock_name_score_sort)\n",
    "    \n",
    "    print(f'days: {max_days}')\n",
    "    print('-'*100)\n",
    "    int_check = 0\n",
    "    for k,v in dict_stock_name_score_sort.items():\n",
    "        dict_pair_daywithscore['stock_score'].append(k)\n",
    "        print(k,v)\n",
    "        int_check+=1\n",
    "        if int_check >=10:\n",
    "            break\n",
    "    print('-'*100)\n",
    "\n",
    "    # pair\n",
    "    print(f'The name of the stock that has reached the lowest price in {config[mode][\"len_data\"]} days')\n",
    "    dict_pair_daywithscore['stock_score'] = dict_pair_daywithscore['stock_score'][:10]\n",
    "    for stock_sc in dict_pair_daywithscore['stock_score']:\n",
    "        if stock_sc in dict_pair_daywithscore['min_date']:\n",
    "            # list_date_less_than_10.append(stock_sc)\n",
    "            print(stock_sc)\n",
    "\n",
    "    # testing\n",
    "    # trend up \n",
    "    dict_stock_trend_up = {}\n",
    "    for tup in dict_pair_daywithscore['min_date']:\n",
    "        dict_stock_trend_up.update({tup:0})\n",
    "\n",
    "    for tup in dict_pair_daywithscore['min_date']:\n",
    "        try:\n",
    "            # data = get_data(tv, key_exc, tup, days)\n",
    "            # data = data.reset_index()\n",
    "            data = load_data(namest, mode, key_exc, t)\n",
    "        except Exception as e:\n",
    "            print(f'stock name: {tup}')\n",
    "            print(f'error: {e}')\n",
    "            continue\n",
    "\n",
    "        score = 0\n",
    "        # first indicators\n",
    "        for indicator in config[mode]['short_indicators']:\n",
    "            # print('indicator:',indicator)\n",
    "            score += indicator_engine.process(f\"{indicator}\", data, indicator_config_short[f'{indicator}'])\n",
    "\n",
    "        dict_stock_trend_up[tup] = score\n",
    "\n",
    "    dict_stock_trend_up_sort = dict(sorted(dict_stock_trend_up.items(), key=lambda item: item[1], reverse=True))\n",
    "    print('the name of stock is trend up')\n",
    "    for k,v in dict_stock_trend_up_sort.items():\n",
    "        print(k,v)\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pythainav as nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "getd = nav.get_all(\"K-GA-A(D)\", asDataFrame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "getd = getd.drop([\"tags\",\"fund\"],axis=1)\n",
    "getd = getd.rename(columns = {'value':'close','updated':'datetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.1239</td>\n",
       "      <td>2022-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.1572</td>\n",
       "      <td>2022-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0949</td>\n",
       "      <td>2022-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.1572</td>\n",
       "      <td>2022-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.2255</td>\n",
       "      <td>2022-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>11.0679</td>\n",
       "      <td>2023-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>11.1364</td>\n",
       "      <td>2023-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>11.1563</td>\n",
       "      <td>2023-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>11.1466</td>\n",
       "      <td>2023-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>11.1294</td>\n",
       "      <td>2023-04-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       close   datetime\n",
       "0    12.1239 2022-04-11\n",
       "1    12.1572 2022-04-12\n",
       "2    12.0949 2022-04-19\n",
       "3    12.1572 2022-04-20\n",
       "4    12.2255 2022-04-21\n",
       "..       ...        ...\n",
       "219  11.0679 2023-03-31\n",
       "220  11.1364 2023-04-03\n",
       "221  11.1563 2023-04-04\n",
       "222  11.1466 2023-04-05\n",
       "223  11.1294 2023-04-11\n",
       "\n",
       "[224 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getd\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cal_number_days = getd[getd['close'] == min(list(getd['close']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_min_value = pd.to_datetime(data_cal_number_days['datetime'].values[0]).to_pydatetime().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('stock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62bf5572cc101ed9ae4fde5815e6644554f95a90271476078347a0a4f775b5be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
