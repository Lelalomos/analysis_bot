{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvDatafeed import TvDatafeed,Interval\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from trade import cross_ema, ichimoku_cloud, macd_crossrsi, collect_mtfssl_pvtdiver, macd_ssl_vwap, adxdi_crossrsi\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "import talib\n",
    "# from talib.abstract import EMA, MACD\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "tv = TvDatafeed(username=None,password=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeout: _ssl.c:1112: The handshake operation timed out\n",
    "def get_data(tv, exchange, name_stock, n_bars):\n",
    "    return tv.get_hist(name_stock, exchange, interval=Interval.in_daily, n_bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "list_stock = list()\n",
    "# list stock config\n",
    "with open(os.path.join(os.getcwd(),'config','list_stock','stock_config.json')) as f:\n",
    "    json_stock = json.load(f)\n",
    "\n",
    "assert json_stock is not None, \"error read stock config\"\n",
    "\n",
    "# indicator config\n",
    "with open(os.path.join(os.getcwd(),'config','indicator','indicator.json')) as f:\n",
    "    indicator_config = json.load(f)\n",
    "\n",
    "assert indicator_config is not None, \"error read indicator config\"\n",
    "\n",
    "config = {\n",
    "    \"find-min\": True,\n",
    "    \"find-max\": True\n",
    "}\n",
    "\n",
    "# loop key score\n",
    "dict_stock_name_score = {}\n",
    "dict_min_value_1 = {}\n",
    "dict_min_value_2 = {}\n",
    "dict_remaining_date = {}\n",
    "\n",
    "for key_exc in json_stock['list_stock']:\n",
    "    for namest in json_stock['list_stock'][key_exc]:\n",
    "        dict_stock_name_score.update({namest:0})\n",
    "\n",
    "print('dict_stock_name_score:',dict_stock_name_score)\n",
    "# find current date\n",
    "current_date = datetime.datetime.today().date()\n",
    "\n",
    "for key_exc in json_stock['list_stock']:\n",
    "    print(f'exchange: {key_exc}')\n",
    "    for namest in json_stock['list_stock'][key_exc]:\n",
    "        try:\n",
    "            data = get_data(tv, key_exc, namest, 1000)\n",
    "            data = data.reset_index()\n",
    "            print(f'stock name: {namest}:{len(data)}')\n",
    "        except Exception as e:\n",
    "            print(f'stock name: {namest}')\n",
    "            print(f'error: {e}')\n",
    "            continue\n",
    "        \n",
    "        score_ema = 0\n",
    "        score_mtfssl_pvtdiver = 0\n",
    "        score_adxdi_crossrsi = 0\n",
    "        score_macd_crossrsi = 0\n",
    "        for iconfig in indicator_config['ema']:\n",
    "            try:\n",
    "                result_ema = cross_ema(df = data, namest = namest, **iconfig)\n",
    "            except Exception as e:\n",
    "                print(f'error {namest} cross_ema: {e}')\n",
    "            score_ema += result_ema[0]\n",
    "\n",
    "            try:\n",
    "                retsult_adxdi = adxdi_crossrsi(data, iconfig['low_span'], iconfig['long_span'])\n",
    "            except Exception as e:\n",
    "                print(f'error {namest} adxdi_crossrsi: {e}')\n",
    "            score_adxdi_crossrsi+=retsult_adxdi\n",
    "\n",
    "            try:\n",
    "                result_macd = macd_crossrsi(data, iconfig['low_span'], iconfig['long_span'])\n",
    "            except Exception as e:\n",
    "                print(f'error {namest} macd_crossrsi: {e}')\n",
    "            score_macd_crossrsi+=result_macd\n",
    "\n",
    "            for day in [30, 60, 90]:\n",
    "                try:\n",
    "                    result_mtfssl_pvtdiver = collect_mtfssl_pvtdiver(data, iconfig['low_span'],iconfig['long_span'], day)\n",
    "                except Exception as e:\n",
    "                    print(f'error {namest} collect_mtfssl_pvtdiver: {e}')\n",
    "                score_mtfssl_pvtdiver += result_mtfssl_pvtdiver\n",
    "\n",
    "        try:\n",
    "            result_macd_ssl_vwap = macd_ssl_vwap(data)\n",
    "        except Exception as e:\n",
    "            print(f'error {namest} macd_ssl_vwap: {e}')\n",
    "\n",
    "        try:    \n",
    "            result_ichimoku = ichimoku_cloud(df = data, namest = namest)\n",
    "        except Exception as e:\n",
    "            print(f'error {namest} ichimoku_cloud: {e}')\n",
    "\n",
    "        # try:\n",
    "        #     result_macd = macd(df = data, namest= namest)\n",
    "        # except Exception as e:\n",
    "        #     print(f'error {namest} macd: {e}')\n",
    "        \n",
    "        if score_mtfssl_pvtdiver > 6:\n",
    "                score_mtfssl_pvtdiver = 5\n",
    "\n",
    "        dict_stock_name_score[namest] = dict_stock_name_score[namest] + score_ema + result_ichimoku[0] + score_macd_crossrsi + score_mtfssl_pvtdiver + result_macd_ssl_vwap + score_adxdi_crossrsi\n",
    "\n",
    "        # find row with the least close value \n",
    "        # df = df[df['close'] == min(list(df['close']))] \n",
    "\n",
    "        # find date with the least value in data. do it every month\n",
    "        list_time = [62, 93]\n",
    "        for t in list_time:\n",
    "            data_follow_time = get_data(tv, key_exc, namest, t)\n",
    "            data_follow_time = data_follow_time.reset_index()\n",
    "\n",
    "            # find min value in dataframe\n",
    "            data_cal_number_days = data_follow_time[data_follow_time['close'] == min(list(data_follow_time['close']))]\n",
    "            # convert timestamp to datetime.date\n",
    "            if len(data_cal_number_days) > 1:\n",
    "                data_cal_number_days = data_cal_number_days.iloc[-1,:]\n",
    "                date_min_value = data_cal_number_days['datetime'].to_pydatetime().date()\n",
    "            else:\n",
    "                # convert numpy.datetime64 to datetime\n",
    "                date_min_value = pd.to_datetime(data_cal_number_days['datetime'].values[0]).to_pydatetime().date()\n",
    "            # date_min_value = data_cal_number_days['datetime'].to_pydatetime().date()\n",
    "            remaining_date = current_date - date_min_value\n",
    "            \n",
    "            df_min_value = data_follow_time[data_follow_time['close'] == min(list(data_follow_time['close']))]\n",
    "            df_current_value = data_follow_time.iloc[-2:-1,:]\n",
    "            if t == 62:\n",
    "                dict_min_value_1[namest] = df_current_value['close'].values[0] - min(list(data_follow_time['close']))\n",
    "                dict_remaining_date[namest] = remaining_date.days\n",
    "            else:\n",
    "                dict_min_value_2[namest] = df_current_value['close'].values[0] - min(list(data_follow_time['close']))\n",
    "                dict_remaining_date[namest] = remaining_date.days\n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "# remove data\n",
    "\n",
    "# sort data by current close value minus the smallest a value in the past\n",
    "dict_min_value_1_sort = dict(sorted(dict_min_value_1.items(), key=lambda item: item[1], reverse=True))\n",
    "dict_min_value_2_sort = dict(sorted(dict_min_value_2.items(), key=lambda item: item[1], reverse=True))\n",
    "# sort data remaining date\n",
    "dict_remaining_date_sort = dict(sorted(dict_remaining_date.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "print('-'*100)\n",
    "print('dict_min_value_1_sort:',dict_min_value_1_sort)\n",
    "print('-'*100)\n",
    "\n",
    "print('result step 1:',dict_stock_name_score)\n",
    "\n",
    "# loop increase score\n",
    "for dict_sort_value in [dict_min_value_1_sort, dict_min_value_2_sort, dict_remaining_date_sort]:\n",
    "    # normalize score\n",
    "    list_score = [i*100 for i in range(1,len(dict_sort_value)+1)]\n",
    "    np_score = np.array(list_score)\n",
    "    normalized_arr = preprocessing.normalize([np_score])\n",
    "\n",
    "\n",
    "    dict_score = {} \n",
    "    for score,(k,v) in zip(normalized_arr.tolist()[0],dict_sort_value.items()):\n",
    "        dict_score.update({k:score})\n",
    "\n",
    "    for k,v in dict_score.items():\n",
    "        dict_stock_name_score[k] = dict_stock_name_score[k] + dict_score[k]\n",
    "\n",
    "\n",
    "dict_stock_name_score_sort = dict(sorted(dict_stock_name_score.items(), key=lambda item: item[1], reverse=True))\n",
    "print('-'*100)\n",
    "for k,v in dict_stock_name_score_sort.items():\n",
    "    print(k,v)\n",
    "print('-'*100)\n",
    "\n",
    "# score date buy last day\n",
    "\n",
    "\n",
    "# score distance between min close value and close value have to buy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2\n",
    "\n",
    "# list stock config\n",
    "with open(os.path.join(os.getcwd(),'config','list_stock','stock_config.json')) as f:\n",
    "    json_stock = json.load(f)\n",
    "\n",
    "assert json_stock is not None, \"error read stock config\"\n",
    "\n",
    "\n",
    "# indicator config\n",
    "with open(os.path.join(os.getcwd(),'config','indicator','indicator.json')) as f:\n",
    "    indicator_config = json.load(f)\n",
    "\n",
    "assert indicator_config is not None, \"error read indicator config\"\n",
    "\n",
    "# config\n",
    "with open(os.path.join(os.getcwd(),'config','config.json')) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "assert config is not None, \"error read config\"\n",
    "\n",
    "# print('dict_stock_name_score:',dict_stock_name_score)\n",
    "# find current date\n",
    "current_date = datetime.datetime.today().date()\n",
    "\n",
    "list_time = [62, 93, 124, 155]\n",
    "\n",
    "for days in config['len_data']:\n",
    "    for key_exc in json_stock['list_stock']:\n",
    "        print(f'exchange: {key_exc}')\n",
    "\n",
    "        dict_min_value_1 = {}\n",
    "        dict_min_value_2 = {}\n",
    "        dict_remaining_date = {}\n",
    "        dict_pair_daywithscore = {\n",
    "            \"stock_score\":[],\n",
    "            \"min_date\":[]\n",
    "        }\n",
    "\n",
    "        dict_stock_name_score = {}\n",
    "        for namest2dict in json_stock['list_stock'][key_exc]:\n",
    "            dict_stock_name_score.update({namest2dict:0})\n",
    "            dict_remaining_date.update({namest2dict:{}})\n",
    "            for t in list_time:\n",
    "                dict_remaining_date[namest2dict].update({f\"{t}\":0})\n",
    "\n",
    "        for namest in json_stock['list_stock'][key_exc]:\n",
    "            try:\n",
    "                data = get_data(tv, key_exc, namest, days)\n",
    "                data = data.reset_index()\n",
    "                len_data = len(data)\n",
    "                print(f'stock name: {namest}:{len(data)}')\n",
    "            except Exception as e:\n",
    "                print(f'stock name: {namest}')\n",
    "                print(f'error: {e}')\n",
    "                continue\n",
    "\n",
    "            score_ema = 0\n",
    "            score_mtfssl_pvtdiver = 0\n",
    "            score_adxdi_crossrsi = 0\n",
    "            score_macd_crossrsi = 0\n",
    "            for iconfig in indicator_config['ema']:\n",
    "                try:\n",
    "                    result_ema = cross_ema(df = data, namest = namest, **iconfig)\n",
    "                except Exception as e:\n",
    "                    print(f'error {namest} cross_ema: {e}')\n",
    "                score_ema += result_ema[0]\n",
    "\n",
    "                try:\n",
    "                    retsult_adxdi = adxdi_crossrsi(data, iconfig['low_span'], iconfig['long_span'])\n",
    "                except Exception as e:\n",
    "                    print(f'error {namest} adxdi_crossrsi: {e}')\n",
    "                score_adxdi_crossrsi+=retsult_adxdi\n",
    "\n",
    "                try:\n",
    "                    result_macd = macd_crossrsi(data, iconfig['low_span'], iconfig['long_span'])\n",
    "                except Exception as e:\n",
    "                    print(f'error {namest} macd_crossrsi: {e}')\n",
    "                score_macd_crossrsi+=result_macd\n",
    "\n",
    "                for day in [30, 60, 90]:\n",
    "                    try:\n",
    "                        result_mtfssl_pvtdiver = collect_mtfssl_pvtdiver(data, iconfig['low_span'],iconfig['long_span'], day)\n",
    "                    except Exception as e:\n",
    "                        print(f'error {namest} collect_mtfssl_pvtdiver: {e}')\n",
    "                    score_mtfssl_pvtdiver += result_mtfssl_pvtdiver\n",
    "\n",
    "            try:\n",
    "                result_macd_ssl_vwap = macd_ssl_vwap(data)\n",
    "            except Exception as e:\n",
    "                print(f'error {namest} macd_ssl_vwap: {e}')\n",
    "\n",
    "            try:    \n",
    "                result_ichimoku = ichimoku_cloud(df = data, namest = namest)\n",
    "            except Exception as e:\n",
    "                print(f'error {namest} ichimoku_cloud: {e}')\n",
    "\n",
    "            # try:\n",
    "            #     result_macd = macd(df = data, namest= namest)\n",
    "            # except Exception as e:\n",
    "            #     print(f'error {namest} macd: {e}')\n",
    "            \n",
    "            if score_mtfssl_pvtdiver > 6:\n",
    "                    score_mtfssl_pvtdiver = 5\n",
    "\n",
    "            dict_stock_name_score[namest] = dict_stock_name_score[namest] + score_ema + result_ichimoku[0] + score_macd_crossrsi + score_mtfssl_pvtdiver + result_macd_ssl_vwap + score_adxdi_crossrsi\n",
    "\n",
    "            # print('dict_stock_name_score:', dict_stock_name_score)\n",
    "            # find row with the least close value \n",
    "            # df = df[df['close'] == min(list(df['close']))] \n",
    "\n",
    "            # find date with the least value in data. do it every month\n",
    "            for t in list_time:\n",
    "                data_follow_time = get_data(tv, key_exc, namest, t)\n",
    "                data_follow_time = data_follow_time.reset_index()\n",
    "\n",
    "                # find min value in dataframe\n",
    "                data_cal_number_days = data_follow_time[data_follow_time['close'] == min(list(data_follow_time['close']))]\n",
    "                # convert timestamp to datetime.date\n",
    "                if len(data_cal_number_days) > 1:\n",
    "                    data_cal_number_days = data_cal_number_days.iloc[-1,:]\n",
    "                    date_min_value = data_cal_number_days['datetime'].to_pydatetime().date()\n",
    "                else:\n",
    "                    # convert numpy.datetime64 to datetime\n",
    "                    date_min_value = pd.to_datetime(data_cal_number_days['datetime'].values[0]).to_pydatetime().date()\n",
    "                # date_min_value = data_cal_number_days['datetime'].to_pydatetime().date()\n",
    "                remaining_date = current_date - date_min_value\n",
    "                \n",
    "                df_min_value = data_follow_time[data_follow_time['close'] == min(list(data_follow_time['close']))]\n",
    "                df_current_value = data_follow_time.iloc[-2:-1,:]\n",
    "                if t == 62:\n",
    "                    dict_remaining_date[namest][f'{t}'] = remaining_date.days\n",
    "                    dict_min_value_1[namest] = df_current_value['close'].values[0] - min(list(data_follow_time['close']))\n",
    "                else:\n",
    "                    dict_remaining_date[namest][f'{t}'] = remaining_date.days\n",
    "                    dict_min_value_2[namest] = df_current_value['close'].values[0] - min(list(data_follow_time['close']))\n",
    "                \n",
    "        # sort data by current close value minus the smallest a value in the past\n",
    "        dict_min_value_1_sort = dict(sorted(dict_min_value_1.items(), key=lambda item: item[1], reverse=True))\n",
    "        dict_min_value_2_sort = dict(sorted(dict_min_value_2.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        # increse score following by date\n",
    "        dict_prepare_sort = {}\n",
    "        score_follow_time = 0.5\n",
    "        for data_v in list_time:\n",
    "            for key,_ in dict_remaining_date.items():\n",
    "                dict_prepare_sort[key] = dict_remaining_date[key][f\"{data_v}\"]\n",
    "            \n",
    "            dict_remaining_date_sort = dict(sorted(dict_prepare_sort.items(), key=lambda item: item[1],reverse=True))\n",
    "            list_score = [i+score_follow_time for i in range(10)]\n",
    "\n",
    "            reverse_date_tomin_first = dict(sorted(dict_remaining_date_sort.items(), key=lambda item: item[1]))\n",
    "            \n",
    "            print('min close value of number of day: ',data_v)\n",
    "            for k,v in reverse_date_tomin_first.items():\n",
    "                if int(v) <= 10:\n",
    "                    dict_pair_daywithscore['min_date'].append(k)\n",
    "                    print(k,v)\n",
    "            print('stock min day:',dict_pair_daywithscore['min_date'])\n",
    "            print('-'*100)\n",
    "\n",
    "            for add_score, key_score in zip(list_score,list(dict_remaining_date_sort.keys())[:10]):\n",
    "                dict_stock_name_score[key_score] = dict_stock_name_score[key_score] + add_score\n",
    "\n",
    "            score_follow_time+=0.5\n",
    "            \n",
    "\n",
    "        # print('dict_remaining_date_sort:',dict_remaining_date_sort)\n",
    "\n",
    "        # print('-'*100)\n",
    "        # print('dict_min_value_1_sort:',dict_min_value_1_sort)\n",
    "        # print('-'*100)\n",
    "\n",
    "        # print('result step 1:',dict_stock_name_score)\n",
    "\n",
    "        # loop increase score\n",
    "        for dict_sort_value in [dict_min_value_1_sort, dict_min_value_2_sort]:\n",
    "            # print('dict_sort_value:',dict_sort_value)\n",
    "            # normalize score\n",
    "            list_score = [i*1000 for i in range(1,len(dict_sort_value)+1)]\n",
    "            np_score = np.array(list_score)\n",
    "            normalized_arr = preprocessing.normalize([np_score])\n",
    "            # print('normalize:',normalized_arr.tolist()[0])\n",
    "\n",
    "            dict_score = {} \n",
    "            for score,(k,v) in zip(normalized_arr.tolist()[0],dict_sort_value.items()):\n",
    "                dict_score.update({k:score})\n",
    "\n",
    "            # print('dict_score:',dict_score)\n",
    "            for k,v in dict_score.items():\n",
    "                dict_stock_name_score[k] = dict_stock_name_score[k] + dict_score[k]\n",
    "\n",
    "\n",
    "        # print('score:',dict_stock_name_score)\n",
    "        dict_stock_name_score_sort = dict(sorted(dict_stock_name_score.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "        # print('dict_stock_name_score_sort final:',dict_stock_name_score_sort)\n",
    "        \n",
    "        print(f'days: {days}')\n",
    "        print('-'*100)\n",
    "        int_check = 0\n",
    "        for k,v in dict_stock_name_score_sort.items():\n",
    "            dict_pair_daywithscore['stock_score'].append(k)\n",
    "            print(k,v)\n",
    "            int_check+=1\n",
    "            if int_check >=10:\n",
    "                break\n",
    "        print('-'*100)\n",
    "\n",
    "        # pair\n",
    "        print('... date and score ...')\n",
    "        dict_pair_daywithscore['stock_score'] = dict_pair_daywithscore['stock_score'][:10]\n",
    "        for stock_sc in dict_pair_daywithscore['stock_score']:\n",
    "            if stock_sc in dict_pair_daywithscore['min_date']:\n",
    "                # list_date_less_than_10.append(stock_sc)\n",
    "                print(stock_sc)\n",
    "        \n",
    "        # looking for opportunities of stock min day for the graph to go up\n",
    "        # EMA MACD\n",
    "        # print('short term for min date')\n",
    "\n",
    "        # short_term = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # for k1,_ in dict_stock_name_score_sort.items():\n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "# version 3\n",
    "from trade_algorithm import indicators\n",
    "from tvDatafeed import TvDatafeed,Interval\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "tv = TvDatafeed(username=None,password=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeout: _ssl.c:1112: The handshake operation timed out\n",
    "def get_data(tv, exchange, name_stock, n_bars):\n",
    "    return tv.get_hist(name_stock, exchange, interval=Interval.in_daily, n_bars=n_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exchange: SET\n",
      "stock name: bbl:365\n",
      "indicator: cross_ema\n",
      "indicator: cross_rsi\n",
      "indicator: macd\n",
      "indicator: ichimoku_cloud\n",
      "indicator: collect_mtfssl_pvtdiver\n",
      "score: 4\n"
     ]
    }
   ],
   "source": [
    "# list stock config\n",
    "with open(os.path.join(os.getcwd(),'config','list_stock','stock_test.json')) as f:\n",
    "    json_stock = json.load(f)\n",
    "\n",
    "assert json_stock is not None, \"error read stock config\"\n",
    "\n",
    "\n",
    "# indicator config\n",
    "with open(os.path.join(os.getcwd(),'config','indicator','indicator.json')) as f:\n",
    "    indicator_config = json.load(f)\n",
    "\n",
    "assert indicator_config is not None, \"error read indicator config\"\n",
    "\n",
    "# config\n",
    "with open(os.path.join(os.getcwd(),'config','config.json')) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "assert config is not None, \"error read config\"\n",
    "\n",
    "# print('dict_stock_name_score:',dict_stock_name_score)\n",
    "# find current date\n",
    "current_date = datetime.datetime.today().date()\n",
    "\n",
    "list_time = [62, 93, 124, 155]\n",
    "indicator_engine = indicators()\n",
    "\n",
    "for days in config['len_data']:\n",
    "    for key_exc in json_stock['list_stock']:\n",
    "        print(f'exchange: {key_exc}')\n",
    "\n",
    "        dict_min_value_1 = {}\n",
    "        dict_min_value_2 = {}\n",
    "        dict_remaining_date = {}\n",
    "        dict_pair_daywithscore = {\n",
    "            \"stock_score\":[],\n",
    "            \"min_date\":[]\n",
    "        }\n",
    "\n",
    "        dict_stock_name_score = {}\n",
    "        for namest2dict in json_stock['list_stock'][key_exc]:\n",
    "            dict_stock_name_score.update({namest2dict:0})\n",
    "            dict_remaining_date.update({namest2dict:{}})\n",
    "            for t in list_time:\n",
    "                dict_remaining_date[namest2dict].update({f\"{t}\":0})\n",
    "\n",
    "        for namest in json_stock['list_stock'][key_exc]:\n",
    "            try:\n",
    "                data = get_data(tv, key_exc, namest, days)\n",
    "                data = data.reset_index()\n",
    "                len_data = len(data)\n",
    "                print(f'stock name: {namest}:{len(data)}')\n",
    "            except Exception as e:\n",
    "                print(f'stock name: {namest}')\n",
    "                print(f'error: {e}')\n",
    "                continue\n",
    "\n",
    "            score = 0\n",
    "            for indicator in config['inducators']:\n",
    "                print('indicator:',indicator)\n",
    "                score += indicator_engine.process(f\"{indicator}\", data, indicator_config[f'{indicator}'])\n",
    "                \n",
    "            print('score:',score)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def test_1(self,num):\n",
    "        o = 5\n",
    "        for i in range(num):\n",
    "            o+=i\n",
    "        return o\n",
    "    \n",
    "    def loop(self, name):\n",
    "        r = eval(f\"self.{name}\")(3)\n",
    "        return r\n",
    "\n",
    "        \n",
    "cc = test()\n",
    "cc.loop(\"test_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('stock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62bf5572cc101ed9ae4fde5815e6644554f95a90271476078347a0a4f775b5be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
